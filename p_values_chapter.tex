\documentclass{book}
 
%Russian-specific packages
%--------------------------------------
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian,english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{natbib}
%--------------------------------------
 
%Hyphenation rules
%--------------------------------------
%\usepackage{hyphenat}https://www.overleaf.com/project/5ef97fb2c79eda000172460d
%\hyphenation{ма-те-ма-ти-ка вос-ста-нав-ли-вать доп-пель-ган-гер гене-тика обще-научном}
%--------------------------------------
 
\usepackage{graphicx}
\begin{document}
\selectlanguage{russian}
%\tableofcontents

\chapter[Что такое не везёт: p-values]{Что такое не везёт и как это рассчитывать: p-values}

\section*{Cтатистическая значимость}

Словосочетание <<статистическая значимость>> (или его психологического доппельгангера, <<достоверность>>), наверное, слышали все. Медицина, генетика, опросы про зубную пасту и против зубной пасты - весь этот поток информации без статистики и без сравнения гипотез (вот для чего нужна значимость) превращается в хаос разнообразных наборов данных.

Слово <<статистика>> имеет несколько значений. К более техническому, важному для нас, мы вернёмся позже, а сейчас поговорим немного об общенаучном. Статистика и теория вероятности - это связанные способы исследования закономерностей мира. Теория вероятностей предсказывает события, исходя из моделей, и так пытается понять то, что мы видим вокруг. Монетка, игральная кость, нормальное распределение - всё это модели случайных переменных, а исходы этих переменных - это те события, которые мы можем увидеть - орёл, четыре, червяк длиной 4 сантиметра. Статистика же делает для теории вероятности черновую, обратную работу. По наблюдениям оцениваются параметры модели (об этом мы много говорили об этом в предыдущей главе), и проверяются гипотезы о пригодности модели для описания наблюдений. 

\section*{Сравнение гипотез}

Если мы одновременно думали о нескольких гипотезах (их может быть сколько угодно, но двух взаимоисключающих гипотез $\text{В} \equiv \text{!A}$ достаточно, чтоб понять, что происходит), и мы только что провели новое наблюдение  (поставили опыт, взломали сайт, посчитали попугаев), то наше доверие к каждой из этих гипотез претерпело некоторые изменения от столкновения с реальностью, представленной результатом наблюдения.  

\begin{align}\label{hyp_compare_bayes_A}
   &P\left(\text{A|obs}\right)=
   \frac{P\left(\text{obs|A}\right) P\left(\text{A}\right)}{P\left(\text{obs}\right)} = \nonumber \\
   &=\frac{P\left(\text{obs|A}\right) P\left(\text{A}\right)}{P\left(\text{obs|A}\right) P\left(\text{A}\right)+P\left(\text{obs|B}\right) P\left(\text{B}\right)} 
\end{align}

\begin{align}\label{hyp_compare_bayes_B}
   &P\left(\text{B|obs}\right)=
   \frac{P\left(\text{obs|B}\right) P\left(\text{B}\right)}{P\left(\text{obs}\right)} = \nonumber \\
   &=\frac{P\left(\text{obs|B}\right) P\left(\text{B}\right)}{P\left(\text{obs|A}\right) P\left(\text{A}\right)+P\left(\text{obs|B}\right) P\left(\text{B}\right)}
\end{align}


$P\left(\text{A|obs}\right)$ -- вероятность того, что $\text{A}$ верна, при условии того (то есть после того), что получен результат наблюдения $\text{obs}$; $P\left(\text{A}\right)$ - это априорная (до наблюдения) вероятность того, что $\text{A}$ верна, $P\left(\text{obs|A}\right)$ - условная вероятность (правдоподобие) получить результат $\text{obs}$, если $\text{A}$ верна. 

Каждая из формул \eqref{hyp_compare_bayes_A} и \eqref{hyp_compare_bayes_B} - это следствие формулы условной вероятности
$\label{bayes}
P\left(\text{U|V}\right)P\left(\text{V}\right)=P\left(\text{UV}\right)=P\left(\text{V|U}\right)P\left(\text{U}\right)
$, которую называют ещё теоремой Байеса. Тут U и V - индикаторы любых двух событий, а UV - индикатор того, что они произошли одновременно. Понятно, что если события независимы, то $P\left(\text{U|V}\right)=P\left(\text{U}\right)$ и формула условной вероятности превращается в формулу для вероятности независимых событий $P\left(\text{UV}\right)=P\left(\text{V}\right)P\left(\text{U}\right)$. Баейсовский подход к теории вероятностей - это построение многоэтажных лабиринтов из таких формул.

Одинаковый знаменатель в формулах \eqref{hyp_compare_bayes_A} и \eqref{hyp_compare_bayes_B} -- это вероятность наблюдения $P\left(\text{obs}\right)$ (в англоязычной литературе она называется evidence). Часто при сравнении гипотез её вообще опускают, и из \eqref{hyp_compare_bayes_A} и \eqref{hyp_compare_bayes_B} получается:
\begin{align*}\label{hyp_compare_bayes_comp}
   &\frac{P\left(\text{A|obs}\right)}{P\left(\text{B|obs}\right)}=\frac{P\left(\text{obs|A}\right) P\left(\text{A}\right)}{P\left(\text{obs|B}\right) P\left(\text{B}\right)}
\end{align*}.

Или просто пишут 
\begin{align*}\label{hyp_compare_bayes_null_prop}
   &P\left(\text{A|obs}\right)\propto P\left(\text{obs|A}\right) P\left(\text{A}\right)
\end{align*}

В каждом байесовском выражении у всех вероятностей справа после <<$\text{|}$>>, мы должны были бы написать длинную цепочку утверждений, при условии которых это выражение имеет смысл. Тут будет такие предположения, как наблюдаемость мира, работоспособность приборов, правильность постановки эксперимента. Для формул \eqref{hyp_compare_bayes_A} и \eqref{hyp_compare_bayes_B} в этот набор входит это ещё и предположение, что верна одна и только одна из гипотез. Обычно мы все эти условия не пишем, потому что договорились считать это очевидным, но иногда, когда модели вложены или параметризованы, явная запись части условий необходима для того, чтобы формулы заработали.  
 
Кстати, полезно иногда думать о том, что справа от вертикальной черты, как о контексте сообщения, а о том, что слева -- как о сообщении. 
 
Пусть у модели, описывающей реальность в предположении о верности гипотезы $A$ (чтобы не плодить обозначения, будем называть модель и её гипотезу одной и той же буквой),  есть параметр $\alpha$. Считаем его апостериорное распределение после наблюдения $\text{obs}$. Это распределение, как и сам параметр $\alpha$, имеет смысл, только если $\text{A}$ верна,
\begin{align}\label{hyp_compare_evid_A}
   P\left(\alpha\text{|obs,A}\right)=\frac{P\left(\text{obs|}\alpha\text{,A}\right) P\left(\alpha\text{|A}\right)}{P\left(\text{obs|A}\right)}
\end{align}
$P\left(\text{obs|A}\right)$ - это evidence в \eqref{hyp_compare_evid_A}, он считается как статистическая сумма по всем возможным значениям $\alpha$ - и эта же условная вероятность - $P\left(\text{obs|A}\right)$ - это значение правдоподобия гипотезы $A$ в \eqref{hyp_compare_bayes_A}. Получается, что когда мы оцениваем апостериорные распределения параметра при условии, что сама гипотеза верна, evidence -- это оценка адекватности гипотезы (модели) наблюдениям. Значение evidence позволяет сравнивать гипотезы \citep[подробнее см.][]{skilling_nested_2006}.

\section*{Нулевые и альтернативные гипотезы}

Семейство моделей, о которых мы говорим (вернее, с пониманием молчим), когда заходит речь о статистической значимости или о p-value -- это модели, соответствующие нулевой гипотезе (Null Hypothesis). Конкретное содержание нулевой гипотезы зависит от контекста наблюдения, но общий смысл всегда один и тот же - всё плохо. Эта оптимистичная мысль объединяет собой все нулевые гипотезы. Лекарство работает так же, как плацебо, преступность не отличается между двумя городами, ген одинаково экспрессируется в разных условия, носители разных аллелей одного локуса одинаково часто болеют чем попало -- всё это примеры нулевых гипотез. 

Если нулевая гипотеза верна, то в эксперименте, мы, конечно, всё равно не увидим идеального сходства условий, идеального совпадения экспрессии генов в разных группах и прочих идеальных вариантов выполнения предположения нулевой гипотезы -- мы получим результат, порождённый шумом. Если же нулевая гипотеза не верна, то мы будем наблюдать некий содержательный сигнал, опять-таки искажённый шумом. Для того, чтобы на основании наблюдения (наблюдений), понять, насколько близка к истине нулевая гипотеза $\text{NULL}$ по сравнению с альтернативной (ненулевой) $\text{!NULL}$, можно использовать формулы условной вероятности \eqref{hyp_compare_bayes_A} - \eqref{hyp_compare_bayes_B}. 

\begin{align}\label{hyp_compare_bayes_null}
   &P\left(\text{NULL|obs}\right)=
   \frac{P\left(\text{obs|NULL}\right) P\left(\text{NULL}\right)}{P\left(\text{obs}\right)} = \nonumber \\
   &=\frac{P\left(\text{obs|NULL}\right) P\left(\text{NULL}\right)}{P\left(\text{obs|NULL}\right) P\left(\text{NULL}\right)+P\left(\text{obs|!NULL}\right) P\left(\text{!NULL}\right)} 
\end{align}

\section*{P-value}
На самом деле, \eqref{hyp_compare_bayes_null} использует редко: для этого нужно уметь оценивать распределение экспериментальных результатов не только для нулевой гипотезы, но и для альтернативной, а это для этого надо знать заранее, как выглядят наблюдения содержательного сигнала. Для того, чтобы можно было сказать хоть что-нибудь о состоятельности нулевой гипотезы, не зная ничего про альтернативные, строят сильно упрощённую оценку, в чём-то родственную Байесовской (об этом ниже). Она-то и будет называться вездесущим словом $p-value$.

Вот как её строят. Если сравнивать нулевую гипотезу с альтернативными мы не можем, то единственная мера адекватности нулевой гипотезы наблюдениям - это вероятность наблюдений при условии того, что нуль-гипотеза верна. Её априорную вероятность при этом вообще не учитывают, как в анекдоте о том, что вероятность того, что за углом стоит тигр, равна $1/2$ - действительно, он же там или стоит, или нет. Ещё одна трудность связана с тем, что вероятность одного значения непрерывной случайной величины - это бесконечно малая величина. Она имеет смысл либо если нам нужно отношение таких вероятностей при разных предположениях, либо если мы интегрируем её на каком-то интервале. Пока в баейсовской формуле мы считали отношения, всё было в порядке, теперь надо задуматься от интервалах.

Самый понятный интервал - это от столба и до обеда. Его и используют при оценке $p-value$: по определению, это вероятность наблюдать тот результат, который был получен, или более маргинальный результат, при условии того, что нулевая гипотеза верна. Очевидно, чтобы оценить p-value по наблюдению, надо знать распределение случайной величины, которая описывает результат нашего наблюдения при верной нулевой гипотезе. Но этого мало: надо ещё понимать, что значит <<более маргинальный>> применительно к нашим наблюдением. 


\begin{figure}
    \centering
    \includegraphics[scale=.5]{img/p-value.png}
    \caption{Площадь красного сегмента графика плотности вероятности случайной величины $\xi$ - это p-value, соответствующее значению $\xi$ на границе сегмента}
    \label{pval}
\end{figure}

\bibliographystyle{apalike}
\bibliography{p-values}

\section*{Куски про ошибки первого рода}


Alexander Favorov, [16.04.21 00:14]
вообще ошибка первого рода возникает в тот момент, когда мы её делаем

Alexander Favorov, [16.04.21 00:15]
В смысле p-value это просто p-value

Alexander Favorov, [16.04.21 00:16]
а дальше если нам пришло в голову почему-то (например, посмотрев на p-value или на звёзды) сказать, что этот эксперимент отверг нулевую гипотезу - вот тут уже мы что - то сделали, ошиблись ли? вероятность этого это вероятность ошибки первого рода

Alexander Favorov, [16.04.21 00:16]
p-val это вообще не про ошибку

Alexander Favorov, [16.04.21 00:17]
это вер-ть получить такое или ещё страннее если нуль-гипотеза верна

Alexander Favorov, [16.04.21 00:19]
При этом не p-val это не  p(obs | H0) а интеграл от obs до предельной кривизны наблюдения  p(x | H0)

Alexander Favorov, [16.04.21 00:19]
где x - воображаемое другое наблюдение

Sergey Isaev, [16.04.21 00:19]
ага понял

Alexander Favorov, [16.04.21 00:19]
Ну, переменная интегрирования она же

Sergey Isaev, [16.04.21 00:19]
дада

Sergey Isaev, [16.04.21 00:20]
Меня вот что смущает, что вот допустим у меня есть два эксперимента, да, и что я их обоих сравниваю с H0, да

Sergey Isaev, [16.04.21 00:20]
И что в одном случае у меня p = 0.001, а в другом p = 0.0000000001

Sergey Isaev, [16.04.21 00:21]
И что во втором случае как будто бы я менее вероятно проебался, чем в первом, когда отвергнул H0

Alexander Favorov, [16.04.21 00:24]
приходит мужик и приносит тест на беременность с двумя полосками :):)

Sergey Isaev, [16.04.21 00:24]
ну или он приносит 20 тестов на беременность с двумя полосками

Sergey Isaev, [16.04.21 00:25]
ну типа во втором случае я как будто бы больше поверю, что он беременный

Alexander Favorov, [16.04.21 00:25]
ну да

Alexander Favorov, [16.04.21 00:25]
но это одна группа тестов примерно

Alexander Favorov, [16.04.21 00:25]
но если ты его сравниваешь с барышней, у которое тоже две полоски, но в одном экземпляре и видно плохо, ты скорее поверишь что барышня

Alexander Favorov, [16.04.21 00:26]
хотя у мужика 20 и видны за километр без очков
\end{document}
